---
title: "Predicting Seasonal Influenza Hospitalizations"
author: "Kevin W. McConeghy, Jason R. Gantenberg, Andrew R. Zullo, Chanelle J. Howe, ... (author list tentative)"
date: "Compiled: `r Sys.Date()`"
output: tint::tintPdf
bibliography: flurefs.bib
link-citations: yes
---

```{r setup, include=FALSE}
library(tint)
library(here)
# invalidate cache when the package version changes
knitr::opts_chunk$set(tidy = FALSE, cache.extra = packageVersion('tint'))
options(htmltools.dir.version = FALSE)
```

# Purpose

To determine which of a set of simple candidate statistical models (CSM) most closely fits a series of hypothetical influenza hospitalization curves (HIHC), stratified by season severity [@Centers_for_Disease_Control_and_Prevention2016-nr].

Which of these simple CSMs would provide the best severity forecast at the beginning of the flu season (i.e., epiweek 40) based purely on fit to the HIHCs described below?

_Subquestion:_ Which model best predicts the proportion of flu-attributable hospitalizations?

# General approach

1. Fit a quadratic trend filter model [@Brooks2015-fl] to FluSurv-NET hospitalization data for the seasons 2003–2004 through 2017–2018, based in part on the approach described by Brooks et al. [@Brooks2015-fl].

1. Simulate 3,000 HIHCs using the empirical Bayes model as a "generative model".  

1. Stratify these HIHCs into groups representing High/Moderate and Mild severity HIHCs, based on the CDC's categorization [@Biggerstaff2018-ns; @Centers_for_Disease_Control_and_Prevention2018-mf].

1. Fit each CSM within each severity stratum and test for goodness of fit. Systematically alter the functional form of epiweek indicators as in Wang et al.’s study of influenza mortality [@Wang2012-am].


# Targets

All weeks will be specified based on the _MMWR_ Week convention [@Centers_for_Disease_Control_and_Prevention_undated-pu]:

1. Peak height (number of hospitalizations)
1. Peak week (week in which maximum number of hospitalizations occurred)
1. Total hospitalizations

These targets follow in part from [@Brooks2015-fl].

```{r flusurv-net_fig, echo = FALSE, fig.fullwidth = TRUE, fig.cap = "Empirical hospitalization curves, peak weeks, and peak number of cases --- 2003--2017 (Source: FluSurv-NET, CDC). Data excludes 2009--2010 pandemic influenza season and 2017--2018 due to no official severity designation."}
knitr::include_graphics("hospital-curve-empirical.pdf")
```

# Curve fitting and simulation

We will simulate HIHCs using a modified version of the curve-fitting approach described by Brooks et al. [@Brooks2015-fl].

First, we fit a quadratic trend filter to historical hospitalization curves released by the CDC (beginning with the 2003--2004 season), using the R package `glmgen` [@Brooks2015-fl; @Centers_for_Disease_Control_and_Prevention2016-nr]. This model is fit within flu severity group (Mild, High/Moderate).

For each season $s$ and each week $i$, Brooks et al. conceptualize a seasonal influenza curve as some function plus noise^[Brook et al. use their method to forecast a current flu season, where $b$ represents the current season's epidemic threshold of weighted influenza-like illness percent. Because hospitalization curves have a lower bound of 0, we drop $b$ from the original equation.]:

$$y^s_i = f^s (i) + \epsilon^s_i, \epsilon \sim N(0, \tau^s),$$

where

$$f^s (i) = \frac{\theta}{\text{max}_j f(j)} \left[ f \left( \frac{i - \mu}{v} + \genfrac{}{}{0pt}{}{\text{arg max }{j}} f (j) \right) \right]$$

\marginnote{\textcolor{red}{\textbf{Note:}} In the Brooks paper, exactly what $j$ stood for was a little unclear. I believe the only sensible interpretation is that it's the indicator for the week in the trend filter predictions $f(j)$ conducted as part of each curve simulation.}

Based on fitting the quadratic trend filtering model to empirical data (i.e., historical CDC flu hospitalization data), we estimate error $\tau^s$:

$$\left( \hat{\tau}^s \right)^2 = \genfrac{}{}{0pt}{}{\text{avg}}{i} \left[ y^s_i - \hat{f}^s (i) \right]^2$$

and then sample from the model, introducing noise for each weekly observation based this estimate of $\tau^2$.

We impose a lower bound of 0 hospitalizations via the following transformation of $\hat{y}^s_i$, which we denoted below as $\hat{z}^s_i$:

$$\hat{z}^s_i = 0.5 \bigg( | \hat{y}^s_i | + \hat{y}^s_i \bigg)$$


## Parameters in quadratic trend filtering model

The HIHCs are simulated using the following sampling scheme for each parameter represented in the model for hospitalization count ($y^s_i$) at each week. Note that all equations are either adapted from or appear in [@Brooks2015-fl].

$$\left< f, o, \nu, \theta, \mu \right>$$

## Shape ($f$)

$$f \sim U \{ \hat{f} : \text{historical season } s \} $$

## Noise ($\sigma$)

$$\sigma \sim U \{\hat{\tau}^s \text{ : historical season } s \}$$

## Peak height ($\theta$)

$$\theta \sim U\left[\theta_m , \theta_M\right]$$

\marginnote{\textcolor{red}{\textbf{Note:}} Brooks et al. say they get "unbiased estimators" for the minimum ($\theta_m$) and maximum ($\theta_M$) peak heights, respectively. However, given the notation does not seem to indicate that these parameters are estimates, I am using the observed minimum and maximum heights from the CDC data.}

Results in the following curve:

$$f_3(i) = f_2(i - \mu + \text{arg max}_j f_2(j))$$

## Pacing ($\nu$)

Curve-stretching around peak week:

$$\nu \sim U[0.75, 1.25]$$

Results in following curve:

$$f_4 (i) = f_3 \left( \frac{i - \text{arg max}_j \text{ } f_3 (j)}{\nu} + \text{arg max}_j \text{ } f_3 (j) \right)$$


# Candidate models

\marginnote{\textbf{\textcolor{red}{Question for Kevin:}} I've removed the rate-difference model. Can you think of another model we might want to test? My suspicion is that a linear model with quadratic and other terms may be too close to the Serfling models. I'm still getting through his original paper, though.}

## Serfling model (least squares)

Modified from [@McConeghy_undated-ps]:

$$Y = \beta_0 \alpha + \beta_1 t + \beta_rX_r + ... + \beta_p cos \left( \frac{2 \pi t}{52} \right) + \beta_q sin \left( \frac{2 \pi t}{52} \right)$$

Where $t$ = time (epiweek), subscript $r$ denotes a vector of $\beta$ coefficients and variables, and subscripts $p$ and $q$ take on particular numbers based on the length of $r$.


## Modified Serfling model

Modified from [@McConeghy_undated-ps]:

$$y = \alpha_0 + \beta_1 t + \beta_2 Flu_t + \beta_p X_p + ... + sin \left( \frac{2 \pi t}{period} \right) + cos \left( \frac{2 \pi t}{period} \right) + u$$

Where $t$ = time (epiweek) and subscript $p$ denotes a vector of $beta$ coefficients and variables.


## Generalized additive model (Prophet)

This model will be implemented using the R package _prophet_ [@Taylor2018-pl], which implements a generalized additive modeling approach developed by engineers at Facebook, Inc.

The general form of the equation that will be fit to the HIHCs:

$$y(t)= g(t) + ... + h(t) + \epsilon_t,$$

where $g(t)$ models nonperiod trends and $h(t)$ stands for a vector of holidays or other events that are known to correlate with flu hospitalization [@Brooks2015-fl]. As with the Serfling and modified Serfling models, the Prophet model will include additional model terms included to improve fit.


## Model terms

The following model terms will be entered into the vector of covariates considered for each model:

a) Cyclical terms (Serfling, Fourier, etc.)

a) Historical (empirical) flu hospitalizations

a) Historical data on viral activity (NREVSS), outpatient surveillance (ILI-Net)

a) Average weekly temperature

a) Climate factors (e.g., prior summer temperatures)

a) Lags and leads of c) or d)

a) Indicators for weeks of Thanksgiving and/or Christmas [@Brooks2015-fl; @Taylor2018-pl]


# Goodness of fit

- Root mean squared error (RMSE)

- Bayesian information criterion (BIC)

- Relative bias

\marginnote{\textcolor{red}{\bfseries Question for Dr. Naimi:} Should we be doing cross-validation or sample-splitting given the aims of this analysis? We can simulate an arbitrary number of hypothetical hospitalization curves, so the limited number of historical flu season available may not be an issue.}


## Sensitivity analysis

_Challenge_

\noindent
The composition of institutions reflected in the FluSurv-NET has changed over time [@Centers_for_Disease_Control_and_Prevention_undated-vt; @Kandula2019-tg], meaning the FluSurv-NET estimates for influenza-related hospitalizations may not be comparable across time. \bigskip

\noindent
_Response_

\noindent
Redo the analysis three times: one for each set of years in which the same participating institutions reported flu data to CDC. See [@Centers_for_Disease_Control_and_Prevention_undated-vt] for more information.

## Limitations

Brooks et al. showed that their empirical Bayes model improved upon standard lagged CDC predictions for several forecasting targets of the overall influenza curves (season onset, peak week, peak rate/count, duration of season). In adapting their approach to hospitalizations, we should ensure we can achieve similar accuracy.

\footnotesize
